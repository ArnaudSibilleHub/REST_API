{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basics packages import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 401: Unauthorized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[283], line 110\u001b[0m\n\u001b[0;32m    107\u001b[0m request\u001b[38;5;241m.\u001b[39madd_header(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccess_token\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Make the GET request and read the response\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlrq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m         insee_list_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mread())\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 401: Unauthorized"
     ]
    }
   ],
   "source": [
    "#api request get\n",
    "import requests as rq\n",
    "import urllib.request as urlrq\n",
    "import json\n",
    "\n",
    "#https://api.insee.fr/entreprises/sirene/V3/siren?q={requête multicritère}&date={paramètre date}\n",
    "base_url = 'https://api.insee.fr/entreprises/sirene/V3.11/siren?'\n",
    "# way to build \"get\" request = https://www.sirene.fr/static-resources/htm/multi_histo_non_histo_311.html\n",
    "# list of param : https://sirene.fr/static-resources/htm/v_sommaire_311.htm\n",
    "# generate access token : https://api.insee.fr/catalogue/site/themes/wso2/subthemes/insee/pages/help.jag#generer\n",
    "# YRCx*?GrVb9D\n",
    "\n",
    "# list of activities fitting with 66.22Z APE' activity code and which is not (\"-\"\") \"f\" (Fermé) as closed \n",
    "#paramq(1) = 'periode(activitePrincipaleUniteLegale:66.22Z) AND -periode(etatAdministratifEtablissement:F)' \n",
    "#=> error 'InvalidURL: URL can't contain control characters. '/entreprises/sirene/V3.11/siren?q=periode(activitePrincipaleUniteLegale:66.22Z) AND -periode(etatAdministratifEtablissement:F)&date=2025-05-01&curseur=*&nombre=100' (found at least ' ')\n",
    "paramq = 'periode(activitePrincipaleUniteLegale:66.22Z)'\n",
    "dateq = '2025-05-01'\n",
    "# to drive the paging, first request with value '*' curseur = \"*\" => we obtain in header the value to fill in second reuqest to obtain next pages 'curseurSuivant': 'AoEpMzAwOTU4MTEz'\n",
    "curseur0 = ''\n",
    "curseur1 = 'AoEpMzEyNTk2MzIz'\n",
    "curseur2 = 'AoEpMzIwNjMzNTE0'\n",
    "curseur3 = 'AoEpMzI3NTE0OTgw'\n",
    "curseur4 = 'AoEpMzMzNTYwMDQz'\n",
    "curseur5 = 'AoEpMzQxMTgyMzg0'\n",
    "curseur6 = 'AoEpMzQ4MzY3Mzg0'\n",
    "curseur7 = 'AoEpMzUzMDkwNzA3'\n",
    "curseur8 = 'AoEpMzgxMjk0OTI1'\n",
    "curseur9 =  'AoEpMzg4MDY1MDg4'\n",
    "curseur10 = 'AoEpMzkyMTI0NzA3'\n",
    "curseur11 = 'AoEpMzk4MTUyODAx'\n",
    "curseur12 = 'AoEpNDAxODgxOTY2'\n",
    "curseur13 = 'AoEpNDA4MDYwMjAw'\n",
    "curseur14 = 'AoEpNDEyMTQ1NzQw'\n",
    "curseur15 = 'AoEpNDE4MjcyNjk2'\n",
    "curseur16 = 'AoEpNDIxOTk4MjUz'\n",
    "curseur17 = 'AoEpNDI4MzE2OTk2'\n",
    "curseur18 = 'AoEpNDMyMjI0MDQ2'\n",
    "curseur19 = 'AoEpNDM3ODk1Nzc0'\n",
    "curseur20 = 'AoEpNDQxNzczNTEy'\n",
    "curseur21 = 'AoEpNDQ3OTczNDcw'\n",
    "curseur22 = 'AoEpNDUxODI4MTY0'\n",
    "curseur23 = 'AoEpNDc4NjYxNjcx'\n",
    "curseur24 = 'AoEpNDgxODMxNTg0'\n",
    "curseur25 = 'AoEpNDg1MzQ3MTY1'\n",
    "curseur26 = 'AoEpNDkwMDM3OTE4'\n",
    "curseur27 = 'AoEpNDkzNDY2MjQ3'\n",
    "curseur28 = 'AoEpNDk4NDM4NTYz'\n",
    "curseur29 = 'AoEpNTAxNDcxOTE2'\n",
    "curseur30 = 'AoEpNTAzODA3NTg4'\n",
    "curseur31 = 'AoEpNTA4Nzg5MDQ3'\n",
    "curseur32 = 'AoEpNTExMjU1MjAw'\n",
    "curseur33 = 'AoEpNTE0Mzc3NTA2'\n",
    "curseur34 = 'AoEpNTE5MjQ2ODYy'\n",
    "curseur35 = 'AoEpNTIyNTUwODk2'\n",
    "curseur36 ='AoEpNTI3ODA5Njc3' \n",
    "curseur37 = 'AoEpNTMwNzQ3NjU4'\n",
    "curseur38 = 'AoEpNTMzNzI0NDA3'\n",
    "curseur39 = 'AoEpNTM4NzQxNjUz'\n",
    "curseur40 = 'AoEpNzUwNTgxODYw'\n",
    "curseur41 = 'AoEpNzUzNDk2MzE0'\n",
    "curseur42 = 'AoEpNzg4ODI2MDE0'\n",
    "curseur43 = 'AoEpNzkxMjMxNjcz'\n",
    "curseur44 = 'AoEpNzk0NDc5NTY4'\n",
    "curseur45 = 'AoEpNzk5NDAxOTA2'\n",
    "curseur46 = 'AoEpODAyNjkyMzQz'\n",
    "curseur47 = 'AoEpODA3OTc2NDc3'\n",
    "curseur48 = 'AoEpODEwNDkyMzMw'\n",
    "curseur49 = 'AoEpODEzNTg3MDQ1'\n",
    "curseur50 = 'AoEpODE4MTgyMzM5'\n",
    "curseur51 = 'AoEpODIxMTYzMDQ1'\n",
    "curseur52 = 'AoEpODIxMTYzMDQ1'\n",
    "curseur53 = 'AoEpODI0MjgyNTEx'\n",
    "curseur54 = 'AoEpODI5Mzg2MDEw'\n",
    "curseur55 = 'AoEpODMyNjc3MzIy'\n",
    "curseur56 = 'AoEpODM3NjIxMzgy'\n",
    "curseur57 = 'AoEpODQxMTEzNzcy'\n",
    "curseur58 = 'AoEpODQ0NDkxOTAy'\n",
    "curseur59 = 'AoEpODQ5NjM2OTA3'\n",
    "curseur60 = 'AoEpODUzMDk5MjQw'\n",
    "curseur61 = 'AoEpODc5OTc1Nzg3'\n",
    "curseur62 = 'AoEpODgzMzA4Mzcx'\n",
    "curseur63 = 'AoEpODg5MzY2OTc3'\n",
    "curseur64 = 'AoEpODkyNjI2NjQ5'\n",
    "curseur65 = 'AoEpODk4MDA4ODc1'\n",
    "curseur66 = 'AoEpOTAyMDg2ODU5'\n",
    "curseur67 = 'AoEpOTA3ODk2NDI3'\n",
    "curseur68 = 'AoEpOTExMjQ0MTAx'\n",
    "curseur69 = 'AoEpOTE1MTk2NzM3'\n",
    "curseur70 = 'AoEpOTIxMzQwMTEz'\n",
    "curseur71 = 'AoEpOTQ3NzY1MjM2'\n",
    "curseur72 = 'AoEpOTUyNDY0Mjc5'\n",
    "curseur73 = 'AoEpOTc5OTY5MTkz'\n",
    "curseur74 = 'AoEpOTgzNzAwMDk3'\n",
    "curseur75 = 'AoEpOTk4MTI1NDA1'\n",
    "curseur = 'AoEpOTk4MTI1NDA1'\n",
    "\n",
    "nombre_per_page = '10000'\n",
    "\n",
    "full_url = f\"{base_url}q={paramq}&date={dateq}&curseur={curseur}&nombre={nombre_per_page}\"\n",
    "\n",
    "\n",
    "#generate access token : https://api.insee.fr/catalogue/site/themes/wso2/subthemes/insee/pages/help.jag#generer\n",
    "access_token = 'bcda3843-0c1e-3af7-bdf1-6a36a54bb2d5'\n",
    "\n",
    "# Create a Request object and add the Authorization header through \"add_header\"\n",
    "request = urlrq.Request(full_url)\n",
    "request.add_header(\"Authorization\", f\"Bearer {access_token}\")\n",
    "\n",
    "# Make the GET request and read the response\n",
    "with urlrq.urlopen(request) as response:\n",
    "    try:\n",
    "        insee_list_json = json.loads(response.read())\n",
    "        insee_list_json.pop('header')\n",
    "        \n",
    "        #obtain curseurSuivant in same time than temporarily canceling the previous pop of header(above)\n",
    "        \n",
    "        # print(insee_list_json['header']) to check \n",
    "        for header, value in response.headers.items():\n",
    "            print(f\"{header}: {value}\")\n",
    "    \n",
    "        # Convert the JSON data to a DataFrame\n",
    "        df = pd.DataFrame(insee_list_json)\n",
    "        \n",
    "        # Save every DataFrame to a CSV file to join after all csv files\n",
    "        df.to_csv('insee_list_04_202477.csv', index=False, encoding='utf-8')\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(e)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['insee_list_04_2024.csv', 'insee_list_04_202410.csv', 'insee_list_04_202411.csv', 'insee_list_04_202412.csv', 'insee_list_04_202413.csv', 'insee_list_04_202414.csv', 'insee_list_04_202415.csv', 'insee_list_04_202416.csv', 'insee_list_04_202417.csv', 'insee_list_04_202418.csv', 'insee_list_04_202419.csv', 'insee_list_04_20242.csv', 'insee_list_04_202420.csv', 'insee_list_04_202421.csv', 'insee_list_04_202422.csv', 'insee_list_04_202423.csv', 'insee_list_04_202424.csv', 'insee_list_04_202425.csv', 'insee_list_04_202426.csv', 'insee_list_04_202427.csv', 'insee_list_04_202428.csv', 'insee_list_04_202429.csv', 'insee_list_04_20243.csv', 'insee_list_04_202431.csv', 'insee_list_04_202432.csv', 'insee_list_04_202433.csv', 'insee_list_04_202434.csv', 'insee_list_04_202435.csv', 'insee_list_04_202436.csv', 'insee_list_04_202437.csv', 'insee_list_04_202438.csv', 'insee_list_04_202439.csv', 'insee_list_04_20244.csv', 'insee_list_04_202440.csv', 'insee_list_04_202441.csv', 'insee_list_04_202442.csv', 'insee_list_04_202443.csv', 'insee_list_04_202444.csv', 'insee_list_04_202445.csv', 'insee_list_04_2024456.csv', 'insee_list_04_202447.csv', 'insee_list_04_202448.csv', 'insee_list_04_202449.csv', 'insee_list_04_20245.csv', 'insee_list_04_202450.csv', 'insee_list_04_202451.csv', 'insee_list_04_202452.csv', 'insee_list_04_202453.csv', 'insee_list_04_202454.csv', 'insee_list_04_202455.csv', 'insee_list_04_202456.csv', 'insee_list_04_202457.csv', 'insee_list_04_202458.csv', 'insee_list_04_202459.csv', 'insee_list_04_20246.csv', 'insee_list_04_202460.csv', 'insee_list_04_202461.csv', 'insee_list_04_202462.csv', 'insee_list_04_202463.csv', 'insee_list_04_202464.csv', 'insee_list_04_202465.csv', 'insee_list_04_202466.csv', 'insee_list_04_202467.csv', 'insee_list_04_202468.csv', 'insee_list_04_202469.csv', 'insee_list_04_20247.csv', 'insee_list_04_202470.csv', 'insee_list_04_202471.csv', 'insee_list_04_202472.csv', 'insee_list_04_202473.csv', 'insee_list_04_202474.csv', 'insee_list_04_202475.csv', 'insee_list_04_202476.csv', 'insee_list_04_202477.csv', 'insee_list_04_20248.csv', 'insee_list_04_20249.csv']\n",
      "An error occurred: [WinError 183] Cannot create a file when that file already exists: 'insurers_list_till_04_2024_all'\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#initial state of variables\n",
    "input_files = []\n",
    "directory = 'C:/Users/BGE/Google Drive/GIT/API'\n",
    "\n",
    "#establish a list of files in main directory and transform in pd\n",
    "all_files = os.listdir(directory)\n",
    "all_files = pd.DataFrame(all_files).to_string()\n",
    "\n",
    "#fill input_files with file names concerned by the mergin operation, defined through regex search  \n",
    "input_files = re.findall(r\"insee_list_04_2024.{0,3}\\.csv\", all_files )\n",
    "print(input_files)\n",
    "\n",
    "# define merge function\n",
    "def merge_csv_files(input_files, output_file):\n",
    "    #open main csv fil which will append other files // newline=''\n",
    "    with open(output_file, 'w' ) as output_csv_file:\n",
    "        fieldnames = ['unitesLegales']\n",
    "        writer = csv.writer(output_csv_file)\n",
    "\n",
    "        for input_file in input_files:\n",
    "            with open(input_file, 'r', newline='') as input_csvfile:\n",
    "                reader = csv.reader(input_csvfile)\n",
    "\n",
    "                for row in input_csvfile:\n",
    "                    writer.writerow(row)\n",
    "\n",
    "output_file = 'insee_list_04_2024_all.csv'\n",
    "merge_csv_files(input_files, output_file)\n",
    "\n",
    "try:\n",
    "    os.makedirs('insurers_list_till_04_2024_all')\n",
    "    shutil.move(insee_list_04_2024_all.csv, insurers_list_till_04_2024_all)\n",
    "except FileExistsError as e:\n",
    "    # Handle the exception\n",
    "    print(f\"An error occurred: {e}\")\n",
    "else:\n",
    "    # If no exception occurs, continue execution\n",
    "    print(\"Directory created successfully.\")\n",
    "    # Continue with the rest of your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['insee_list_04_2024.csv', 'insee_list_04_202410.csv', 'insee_list_04_202411.csv', 'insee_list_04_202412.csv', 'insee_list_04_202413.csv', 'insee_list_04_202414.csv', 'insee_list_04_202415.csv', 'insee_list_04_202416.csv', 'insee_list_04_202417.csv', 'insee_list_04_202418.csv', 'insee_list_04_202419.csv', 'insee_list_04_20242.csv', 'insee_list_04_202420.csv', 'insee_list_04_202421.csv', 'insee_list_04_202422.csv', 'insee_list_04_202423.csv', 'insee_list_04_202424.csv', 'insee_list_04_202425.csv', 'insee_list_04_202426.csv', 'insee_list_04_202427.csv', 'insee_list_04_202428.csv', 'insee_list_04_202429.csv', 'insee_list_04_20243.csv', 'insee_list_04_202431.csv', 'insee_list_04_202432.csv', 'insee_list_04_202433.csv', 'insee_list_04_202434.csv', 'insee_list_04_202435.csv', 'insee_list_04_202436.csv', 'insee_list_04_202437.csv', 'insee_list_04_202438.csv', 'insee_list_04_202439.csv', 'insee_list_04_20244.csv', 'insee_list_04_202440.csv', 'insee_list_04_202441.csv', 'insee_list_04_202442.csv', 'insee_list_04_202443.csv', 'insee_list_04_202444.csv', 'insee_list_04_202445.csv', 'insee_list_04_2024456.csv', 'insee_list_04_202447.csv', 'insee_list_04_202448.csv', 'insee_list_04_202449.csv', 'insee_list_04_20245.csv', 'insee_list_04_202450.csv', 'insee_list_04_202451.csv', 'insee_list_04_202452.csv', 'insee_list_04_202453.csv', 'insee_list_04_202454.csv', 'insee_list_04_202455.csv', 'insee_list_04_202456.csv', 'insee_list_04_202457.csv', 'insee_list_04_202458.csv', 'insee_list_04_202459.csv', 'insee_list_04_20246.csv', 'insee_list_04_202460.csv', 'insee_list_04_202461.csv', 'insee_list_04_202462.csv', 'insee_list_04_202463.csv', 'insee_list_04_202464.csv', 'insee_list_04_202465.csv', 'insee_list_04_202466.csv', 'insee_list_04_202467.csv', 'insee_list_04_202468.csv', 'insee_list_04_202469.csv', 'insee_list_04_20247.csv', 'insee_list_04_202470.csv', 'insee_list_04_202471.csv', 'insee_list_04_202472.csv', 'insee_list_04_202473.csv', 'insee_list_04_202474.csv', 'insee_list_04_202475.csv', 'insee_list_04_202476.csv', 'insee_list_04_202477.csv', 'insee_list_04_20248.csv', 'insee_list_04_20249.csv']\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'insee_list_04_2024_all.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[317], line 52\u001b[0m\n\u001b[0;32m     48\u001b[0m                         writer\u001b[38;5;241m.\u001b[39mwriterow(row)\n\u001b[0;32m     51\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsee_list_04_2024_all.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 52\u001b[0m \u001b[43mmerge_csv_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsurers_list_till_04_2024_all\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[317], line 35\u001b[0m, in \u001b[0;36mmerge_csv_files\u001b[1;34m(input_files, output_file)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;66;03m# Skip the header row if it has been written already\u001b[39;00m\n\u001b[0;32m     32\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m header_written:    \n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#open main csv fil which will append other files // newline=''\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m                 \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m output_csv_file:\n\u001b[0;32m     36\u001b[0m                     writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(output_csv_file)\n\u001b[0;32m     37\u001b[0m                     \u001b[38;5;66;03m# writer.writeheader()  # Write header row\u001b[39;00m\n\u001b[0;32m     38\u001b[0m                     \u001b[38;5;66;03m# writer.writerow(input_file)  # Write data row\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'insee_list_04_2024_all.csv'"
     ]
    }
   ],
   "source": [
    "#union all (join)\n",
    "\n",
    "#import packages\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#initial state of variables\n",
    "input_files = []\n",
    "directory = 'C:/Users/BGE/Google Drive/GIT/API'\n",
    "\n",
    "\n",
    "#establish a list of files in main directory and transform in pd\n",
    "all_files = os.listdir(directory)\n",
    "all_files = pd.DataFrame(all_files).to_string()\n",
    "\n",
    "#fill input_files with file names concerned by the mergin operation, defined through regex search  \n",
    "input_files = re.findall(r\"insee_list_04_2024.{0,3}\\.csv\", all_files )\n",
    "print(input_files)\n",
    "\n",
    "# define merge function with csv package\n",
    "def merge_csv_files(input_files, output_file):\n",
    "    # Initialize a flag to track if the header has been written\n",
    "    header_written = False\n",
    "\n",
    "    # open and read csv files coming from API results \n",
    "    for input_file in input_files:\n",
    "        with open(input_file, 'r', newline='') as input_csvfile:\n",
    "            reader = csv.reader(input_csvfile)\n",
    "                \n",
    "        # Skip the header row if it has been written already\n",
    "            if not header_written:    \n",
    "\n",
    "        #open main csv fil which will append other files // newline=''\n",
    "                with open(output_file, 'w', newline='' ) as output_csv_file:\n",
    "                    writer = csv.writer(output_csv_file)\n",
    "                    # writer.writeheader()  # Write header row\n",
    "                    # writer.writerow(input_file)  # Write data row\n",
    "\n",
    "                    for row in reader:\n",
    "                        writer.writerow(row)\n",
    "                header_written = True\n",
    "            else:\n",
    "        # Skip the header row for subsequent files\n",
    "                next(reader)\n",
    "                #create a writer object ready to be appended \n",
    "                with open(output_file, 'a', newline='') as output_csv_file:\n",
    "                    writer = csv.writer(output_csv_file)\n",
    "                    for row in reader:\n",
    "                        writer.writerow(row)\n",
    "\n",
    "\n",
    "output_file = 'insee_list_04_2024_all.csv'\n",
    "merge_csv_files(input_files, output_file)\n",
    "\n",
    "try:\n",
    "    os.makedirs('insurers_list_till_04_2024_all')\n",
    "    shutil.move(insee_list_04_2024_all.csv, insurers_list_till_04_2024_all)\n",
    "except FileExistsError as e:\n",
    "    # Handle the exception\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    \n",
    "else:\n",
    "    # If no exception occurs, continue execution\n",
    "    print(\"Directory created successfully.\")\n",
    "    # Continue with the rest of your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv('insee_list_04_2024_all.csv', dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       unitesLegales\n",
      "0  {'siren': '300975778', 'statutDiffusionUniteLe...\n",
      "1  {'siren': '301008280', 'statutDiffusionUniteLe...\n",
      "2  {'siren': '301017331', 'statutDiffusionUniteLe...\n",
      "3  {'siren': '301030391', 'statutDiffusionUniteLe...\n",
      "4  {'siren': '301041315', 'statutDiffusionUniteLe...\n"
     ]
    }
   ],
   "source": [
    "print(df_csv.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the DataFrame to ensure JSON strings are properly formatted\n",
    "# df['unitesLegales'] = df_csv['unitesLegales'].str.replace(\"'\", '\"')\n",
    "\n",
    "# Convert the string representation of dictionaries to actual dictionaries\n",
    "# df['unitesLegales'] = df_csv['unitesLegales'].apply(lambda x: eval(x))\n",
    "\n",
    "# Normalize the 'unitesLegales' column to flatten the dictionaries into separate columns\n",
    "# df_normalized = pd.json_normalize(df_csv['unitesLegales'])\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "# print(df_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'method' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[492], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert the 'unitesLegales' column from JSON string to DataFrame\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_normalized2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_csv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munitesLegales\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\site-packages\\pandas\\io\\json\\_json.py:780\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    778\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 780\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\site-packages\\pandas\\io\\json\\_json.py:893\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[1;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m filepath_or_buffer\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 893\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\site-packages\\pandas\\io\\json\\_json.py:933\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    926\u001b[0m filepath_or_buffer \u001b[38;5;241m=\u001b[39m stringify_path(filepath_or_buffer)\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_url(filepath_or_buffer)\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_fsspec_url(filepath_or_buffer)\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[0;32m    932\u001b[0m ):\n\u001b[1;32m--> 933\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    941\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    943\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[0;32m    948\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:709\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    706\u001b[0m errors \u001b[38;5;241m=\u001b[39m errors \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;66;03m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_is_binary_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m    710\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;66;03m# validate encoding and errors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:1171\u001b[0m, in \u001b[0;36m_is_binary_mode\u001b[1;34m(handle, mode)\u001b[0m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(handle), text_classes):\n\u001b[0;32m   1169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, _get_binary_io_classes()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'method' is not iterable"
     ]
    }
   ],
   "source": [
    "# Convert the 'unitesLegales' column from JSON string to DataFrame\n",
    "df_normalized2 = pd.read_json(df_csv['unitesLegales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 120 (char 119)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[494], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m df_csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munitesLegales\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munitesLegales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Convert the JSON string in 'unitesLegales' column to Python dictionaries\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df_csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munitesLegales\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_csv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munitesLegales\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Normalize the 'unitesLegales' column to flatten the dictionaries into separate columns\u001b[39;00m\n\u001b[0;32m      8\u001b[0m df_normalized \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(df_csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munitesLegales\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4640\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4762\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4764\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[494], line 5\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m df_csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munitesLegales\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munitesLegales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Convert the JSON string in 'unitesLegales' column to Python dictionaries\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df_csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munitesLegales\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munitesLegales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Normalize the 'unitesLegales' column to flatten the dictionaries into separate columns\u001b[39;00m\n\u001b[0;32m      8\u001b[0m df_normalized \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(df_csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munitesLegales\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 120 (char 119)"
     ]
    }
   ],
   "source": [
    "# Replace single quotes with double quotes in the 'unitesLegales' column\n",
    "df_csv['unitesLegales'] = df_csv['unitesLegales'].str.replace(\"'\", '\"')\n",
    "\n",
    "# Convert the JSON string in 'unitesLegales' column to Python dictionaries\n",
    "df_csv['unitesLegales'] = df_csv['unitesLegales'].apply(lambda x: json.loads(x))\n",
    "\n",
    "# Normalize the 'unitesLegales' column to flatten the dictionaries into separate columns\n",
    "df_normalized = pd.json_normalize(df_csv['unitesLegales'])\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['{\"siren\": \"301008280\", \"statutDiffusionUniteLegale\": \"O\", \"dateCreationUniteLegale\": \"1996-04-01\", \"sigleUniteLegale\": None, \"sexeUniteLegale\": \"M\", \"prenom1UniteLegale\": \"RENE\", \"prenom2UniteLegale\": \"MARCEL\", \"prenom3UniteLegale\": None, \"prenom4UniteLegale\": None, \"prenomUsuelUniteLegale\": \"RENE\", \"pseudonymeUniteLegale\": None, \"identifiantAssociationUniteLegale\": None, \"trancheEffectifsUniteLegale\": None, \"anneeEffectifsUniteLegale\": None, \"dateDernierTraitementUniteLegale\": \"2024-03-22T14:26:06.000\", \"nombrePeriodesUniteLegale\": 5, \"categorieEntreprise\": None, \"anneeCategorieEntreprise\": None, \"periodesUniteLegale\": [{\"dateFin\": None, \"dateDebut\": \"2008-12-31\", \"etatAdministratifUniteLegale\": \"C\", \"changementEtatAdministratifUniteLegale\": True, \"nomUniteLegale\": \"RICHIR\", \"changementNomUniteLegale\": False, \"nomUsageUniteLegale\": None, \"changementNomUsageUniteLegale\": False, \"denominationUniteLegale\": None, \"changementDenominationUniteLegale\": False, \"denominationUsuelle1UniteLegale\": None, \"denominationUsuelle2UniteLegale\": None, \"denominationUsuelle3UniteLegale\": None, \"changementDenominationUsuelleUniteLegale\": False, \"categorieJuridiqueUniteLegale\": \"1000\", \"changementCategorieJuridiqueUniteLegale\": False, \"activitePrincipaleUniteLegale\": \"66.22Z\", \"nomenclatureActivitePrincipaleUniteLegale\": \"NAFRev2\", \"changementActivitePrincipaleUniteLegale\": False, \"nicSiegeUniteLegale\": \"00077\", \"changementNicSiegeUniteLegale\": False, \"economieSocialeSolidaireUniteLegale\": None, \"changementEconomieSocialeSolidaireUniteLegale\": False, \"societeMissionUniteLegale\": None, \"changementSocieteMissionUniteLegale\": False, \"caractereEmployeurUniteLegale\": None, \"changementCaractereEmployeurUniteLegale\": False}, {\"dateFin\": \"2008-12-30\", \"dateDebut\": \"2008-01-01\", \"etatAdministratifUniteLegale\": \"A\", \"changementEtatAdministratifUniteLegale\": False, \"nomUniteLegale\": \"RICHIR\", \"changementNomUniteLegale\": False, \"nomUsageUniteLegale\": None, \"changementNomUsageUniteLegale\": False, \"denominationUniteLegale\": None, \"changementDenominationUniteLegale\": False, \"denominationUsuelle1UniteLegale\": None, \"denominationUsuelle2UniteLegale\": None, \"denominationUsuelle3UniteLegale\": None, \"changementDenominationUsuelleUniteLegale\": False, \"categorieJuridiqueUniteLegale\": \"1000\", \"changementCategorieJuridiqueUniteLegale\": False, \"activitePrincipaleUniteLegale\": \"66.22Z\", \"nomenclatureActivitePrincipaleUniteLegale\": \"NAFRev2\", \"changementActivitePrincipaleUniteLegale\": True, \"nicSiegeUniteLegale\": \"00077\", \"changementNicSiegeUniteLegale\": False, \"economieSocialeSolidaireUniteLegale\": None, \"changementEconomieSocialeSolidaireUniteLegale\": False, \"societeMissionUniteLegale\": None, \"changementSocieteMissionUniteLegale\": False, \"caractereEmployeurUniteLegale\": None, \"changementCaractereEmployeurUniteLegale\": False}, {\"dateFin\": \"2007-12-31\", \"dateDebut\": \"1996-12-25\", \"etatAdministratifUniteLegale\": \"A\", \"changementEtatAdministratifUniteLegale\": False, \"nomUniteLegale\": \"RICHIR\", \"changementNomUniteLegale\": False, \"nomUsageUniteLegale\": None, \"changementNomUsageUniteLegale\": False, \"denominationUniteLegale\": None, \"changementDenominationUniteLegale\": False, \"denominationUsuelle1UniteLegale\": None, \"denominationUsuelle2UniteLegale\": None, \"denominationUsuelle3UniteLegale\": None, \"changementDenominationUsuelleUniteLegale\": False, \"categorieJuridiqueUniteLegale\": \"1000\", \"changementCategorieJuridiqueUniteLegale\": False, \"activitePrincipaleUniteLegale\": \"67.2Z\", \"nomenclatureActivitePrincipaleUniteLegale\": \"NAF1993\", \"changementActivitePrincipaleUniteLegale\": True, \"nicSiegeUniteLegale\": \"00077\", \"changementNicSiegeUniteLegale\": False, \"economieSocialeSolidaireUniteLegale\": None, \"changementEconomieSocialeSolidaireUniteLegale\": False, \"societeMissionUniteLegale\": None, \"changementSocieteMissionUniteLegale\": False, \"caractereEmployeurUniteLegale\": None, \"changementCaractereEmployeurUniteLegale\": False}, {\"dateFin\": \"1996-12-24\", \"dateDebut\": \"1996-04-01\", \"etatAdministratifUniteLegale\": \"A\", \"changementEtatAdministratifUniteLegale\": True, \"nomUniteLegale\": \"RICHIR\", \"changementNomUniteLegale\": False, \"nomUsageUniteLegale\": None, \"changementNomUsageUniteLegale\": False, \"denominationUniteLegale\": None, \"changementDenominationUniteLegale\": False, \"denominationUsuelle1UniteLegale\": None, \"denominationUsuelle2UniteLegale\": None, \"denominationUsuelle3UniteLegale\": None, \"changementDenominationUsuelleUniteLegale\": False, \"categorieJuridiqueUniteLegale\": \"1000\", \"changementCategorieJuridiqueUniteLegale\": True, \"activitePrincipaleUniteLegale\": None, \"nomenclatureActivitePrincipaleUniteLegale\": None, \"changementActivitePrincipaleUniteLegale\": False, \"nicSiegeUniteLegale\": \"00077\", \"changementNicSiegeUniteLegale\": True, \"economieSocialeSolidaireUniteLegale\": None, \"changementEconomieSocialeSolidaireUniteLegale\": False, \"societeMissionUniteLegale\": None, \"changementSocieteMissionUniteLegale\": False, \"caractereEmployeurUniteLegale\": None, \"changementCaractereEmployeurUniteLegale\": False}, {\"dateFin\": \"1996-03-31\", \"dateDebut\": \"1900-01-01\", \"etatAdministratifUniteLegale\": None, \"changementEtatAdministratifUniteLegale\": False, \"nomUniteLegale\": \"RICHIR\", \"changementNomUniteLegale\": False, \"nomUsageUniteLegale\": None, \"changementNomUsageUniteLegale\": False, \"denominationUniteLegale\": None, \"changementDenominationUniteLegale\": False, \"denominationUsuelle1UniteLegale\": None, \"denominationUsuelle2UniteLegale\": None, \"denominationUsuelle3UniteLegale\": None, \"changementDenominationUsuelleUniteLegale\": False, \"categorieJuridiqueUniteLegale\": None, \"changementCategorieJuridiqueUniteLegale\": False, \"activitePrincipaleUniteLegale\": None, \"nomenclatureActivitePrincipaleUniteLegale\": None, \"changementActivitePrincipaleUniteLegale\": False, \"nicSiegeUniteLegale\": None, \"changementNicSiegeUniteLegale\": False, \"economieSocialeSolidaireUniteLegale\": None, \"changementEconomieSocialeSolidaireUniteLegale\": False, \"societeMissionUniteLegale\": None, \"changementSocieteMissionUniteLegale\": False, \"caractereEmployeurUniteLegale\": None, \"changementCaractereEmployeurUniteLegale\": False}]}']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.iloc[1:2, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['insee_list_04_2024.csv', 'insee_list_04_202410.csv', 'insee_list_04_202411.csv', 'insee_list_04_202412.csv', 'insee_list_04_202413.csv', 'insee_list_04_202414.csv', 'insee_list_04_202415.csv', 'insee_list_04_202416.csv', 'insee_list_04_202417.csv', 'insee_list_04_202418.csv', 'insee_list_04_202419.csv', 'insee_list_04_20242.csv', 'insee_list_04_202420.csv', 'insee_list_04_202421.csv', 'insee_list_04_202422.csv', 'insee_list_04_202423.csv', 'insee_list_04_202424.csv', 'insee_list_04_202425.csv', 'insee_list_04_202426.csv', 'insee_list_04_202427.csv', 'insee_list_04_202428.csv', 'insee_list_04_202429.csv', 'insee_list_04_20243.csv', 'insee_list_04_202431.csv', 'insee_list_04_202432.csv', 'insee_list_04_202433.csv', 'insee_list_04_202434.csv', 'insee_list_04_202435.csv', 'insee_list_04_202436.csv', 'insee_list_04_202437.csv', 'insee_list_04_202438.csv', 'insee_list_04_202439.csv', 'insee_list_04_20244.csv', 'insee_list_04_202440.csv', 'insee_list_04_202441.csv', 'insee_list_04_202442.csv', 'insee_list_04_202443.csv', 'insee_list_04_202444.csv', 'insee_list_04_202445.csv', 'insee_list_04_2024456.csv', 'insee_list_04_202447.csv', 'insee_list_04_202448.csv', 'insee_list_04_202449.csv', 'insee_list_04_20245.csv', 'insee_list_04_202450.csv', 'insee_list_04_202451.csv', 'insee_list_04_202452.csv', 'insee_list_04_202453.csv', 'insee_list_04_202454.csv', 'insee_list_04_202455.csv', 'insee_list_04_202456.csv', 'insee_list_04_202457.csv', 'insee_list_04_202458.csv', 'insee_list_04_202459.csv', 'insee_list_04_20246.csv', 'insee_list_04_202460.csv', 'insee_list_04_202461.csv', 'insee_list_04_202462.csv', 'insee_list_04_202463.csv', 'insee_list_04_202464.csv', 'insee_list_04_202465.csv', 'insee_list_04_202466.csv', 'insee_list_04_202467.csv', 'insee_list_04_202468.csv', 'insee_list_04_202469.csv', 'insee_list_04_20247.csv', 'insee_list_04_202470.csv', 'insee_list_04_202471.csv', 'insee_list_04_202472.csv', 'insee_list_04_202473.csv', 'insee_list_04_202474.csv', 'insee_list_04_202475.csv', 'insee_list_04_202476.csv', 'insee_list_04_202477.csv', 'insee_list_04_20248.csv', 'insee_list_04_20249.csv']\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'insee_list_04_2024_all.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[315], line 37\u001b[0m\n",
      "\u001b[0;32m     34\u001b[0m                 writer\u001b[38;5;241m.\u001b[39mwriterow(row)\n",
      "\u001b[0;32m     36\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsee_list_04_2024_all.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;32m---> 37\u001b[0m \u001b[43mmerge_csv_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m     40\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsurers_list_till_04_2024_all\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\n",
      "Cell \u001b[1;32mIn[315], line 28\u001b[0m, in \u001b[0;36mmerge_csv_files\u001b[1;34m(input_files, output_file)\u001b[0m\n",
      "\u001b[0;32m     23\u001b[0m             reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(input_csvfile)\n",
      "\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#open main csv fil which will append other files // newline=''\u001b[39;00m\n",
      "\u001b[1;32m---> 28\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m output_csv_file:\n",
      "\u001b[0;32m     29\u001b[0m             fieldnames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munitesLegales\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;32m     30\u001b[0m             writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictWriter(output_csv_file, fieldnames\u001b[38;5;241m=\u001b[39mfieldnames)\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n",
      "\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    308\u001b[0m     )\n",
      "\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'insee_list_04_2024_all.csv'"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#initial state of variables\n",
    "input_files = []\n",
    "directory = 'C:/Users/BGE/Google Drive/GIT/API'\n",
    "\n",
    "#establish a list of files in main directory and transform in pd\n",
    "all_files = os.listdir(directory)\n",
    "all_files = pd.DataFrame(all_files).to_string()\n",
    "\n",
    "#fill input_files with file names concerned by the mergin operation, defined through regex search  \n",
    "input_files = re.findall(r\"insee_list_04_2024.{0,3}\\.csv\", all_files )\n",
    "print(input_files)\n",
    "\n",
    "# define merge function\n",
    "def merge_csv_files(input_files, output_file):\n",
    "    for input_file in input_files:\n",
    "        with open(input_file, 'r', newline='') as input_csvfile:\n",
    "            reader = csv.reader(input_csvfile)\n",
    "                \n",
    "            \n",
    "\n",
    "#open main csv fil which will append other files // newline=''\n",
    "        with open(output_file, 'w', newline='' ) as output_csv_file:\n",
    "            fieldnames = ['unitesLegales']\n",
    "            writer = csv.DictWriter(output_csv_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()  # Write header row\n",
    "            # writer.writerow(input_file)  # Write data row\n",
    "            for row in input_csvfile:\n",
    "                writer.writerow(row)\n",
    "\n",
    "output_file = 'insee_list_04_2024_all.csv'\n",
    "merge_csv_files(input_files, output_file)\n",
    "\n",
    "try:\n",
    "    os.makedirs('insurers_list_till_04_2024_all')\n",
    "    shutil.move(insee_list_04_2024_all.csv, insurers_list_till_04_2024_all)\n",
    "except FileExistsError as e:\n",
    "    # Handle the exception\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    continue\n",
    "else:\n",
    "    # If no exception occurs, continue execution\n",
    "    print(\"Directory created successfully.\")\n",
    "    # Continue with the rest of your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                               1\n",
      "unitesLegales  {'siren': '301008280', 'statutDiffusionUniteLe...\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for key, value in df_csv.iloc[i].items():\n",
    "    pdRow=pd.DataFrame(df_csv.iloc[i])\n",
    "    # print(list(pdRow.keys()))\n",
    "    # print(list(pdRow.values()))\n",
    "    print(pdRow)\n",
    "    for key, value in enumerate(pdRow):\n",
    "        dictpdRows = pd.DataFrame(pdRow.values)\n",
    "        dictRows = pdRow.values\n",
    "        # print(dictRows)\n",
    "    # Step 1: Accessing the column\n",
    "\n",
    "pdRow_column = df_csv['unitesLegales']\n",
    "\n",
    "# row_values = {print(value) for key, value in enumerate(pdRow_column)}\n",
    "# dict_row_values = {print(value) for value in enumerate(row_values)}\n",
    "# print(dict_row_values)\n",
    "\n",
    "# Step 2: Expanding the dictionary into separate columns\n",
    "pdRow_expanded = pd.DataFrame(pdRow_column.to_list())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#convert JSON object into a dataframe\n",
    "for key, value in enumerate(df_csv.items()):\n",
    "    df = pd.json_normalize(df_csv.iloc[1:1, :].values)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 120 (char 119)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[507], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m df_csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munitesLegales\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munitesLegales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mFalse\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Convert JSON strings to dictionaries\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m df_csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munitesLegales\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_csv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munitesLegales\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Normalize the \"unitesLegales\" column\u001b[39;00m\n\u001b[0;32m     24\u001b[0m df_unites \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(df_csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munitesLegales\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4640\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4762\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4764\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\BGE\\anaconda3\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 120 (char 119)"
     ]
    }
   ],
   "source": [
    "#LAST STAGE 5/12/2024\n",
    "\n",
    "# Assuming 'df' contains the DataFrame with the 'unitesLegales' column\n",
    "# Create a DataFrame from the 'unitesLegales' column\n",
    "df_csv1 = df_csv[ 0 : 0]\n",
    "#1 df_unites = pd.DataFrame(df_csv['unitesLegales'].tolist())\n",
    "#2 df_unites = pd.DataFrame(df_csv['unitesLegales'].values.tolist())\n",
    "#3 df_unites = pd.DataFrame(df_csv['unitesLegales'].values)\n",
    "\n",
    "# Normalize the \"unitesLegales\" column\n",
    "#4 df_unites = pd.concat([pd.json_normalize(x) for x in df_csv['unitesLegales']], ignore_index=True)\n",
    "\n",
    "# Extract dictionaries from the \"unitesLegales\" column\n",
    "#5 df_unites = pd.DataFrame(df_csv['unitesLegales'].apply(pd.Series))\n",
    "\n",
    "# Replace single quotes with double quotes\n",
    "df_csv['unitesLegales'] = df_csv['unitesLegales'].str.replace(\"'\", '\"')\n",
    "\n",
    "# Preprocess the 'unitesLegales' column to convert boolean strings to actual boolean values\n",
    "df_csv['unitesLegales'] = df_csv['unitesLegales'].str.replace('\\'True\\'', 'true').str.replace('\\'False\\'', 'false').str.replace('\\'None\\'', 'none')\n",
    "\n",
    "# Convert JSON strings to dictionaries\n",
    "df_csv['unitesLegales'] = df_csv['unitesLegales'].apply(json.loads)\n",
    "\n",
    "# Normalize the \"unitesLegales\" column\n",
    "df_unites = pd.json_normalize(df_csv['unitesLegales'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_unites)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"siren\": \"300975778\", \"statutDiffusionUniteLegale\": \"O\", \"dateCreationUniteLegale\": \"1900-01-01\", \"sigleUniteLegale\": None, \"sexeUniteLegale\": \"M\", \"prenom1UniteLegale\": \"JEAN\", \"prenom2UniteLegale\": \"JACQUES\", \"prenom3UniteLegale\": None, \"prenom4UniteLegale\": None, \"prenomUsuelUniteLegale\": \"JEAN\", \"pseudonymeUniteLegale\": None, \"identifiantAssociationUniteLegale\": None, \"trancheEffectifsUniteLegale\": None, \"anneeEffectifsUniteLegale\": None, \"dateDernierTraitementUniteLegale\": \"2024-03-22T14:26:06.000\", \"nombrePeriodesUniteLegale\": 4, \"categorieEntreprise\": None, \"anneeCategorieEntreprise\": None, \"periodesUniteLegale\": [{\"dateFin\": None, \"dateDebut\": \"2008-12-31\", \"etatAdministratifUniteLegale\": \"C\", \"changementEtatAdministratifUniteLegale\": True, \"nomUniteLegale\": \"VIALLA\", \"changementNomUniteLegale\": False, \"nomUsageUniteLegale\": None, \"changementNomUsageUniteLegale\": False, \"denominationUniteLegale\": None, \"changementDenominationUniteLegale\": False, \"denominationUsuelle1UniteLegale\": None, \"denominationUsuelle2UniteLegale\": None, \"denominationUsuelle3UniteLegale\": None, \"changementDenominationUsuelleUniteLegale\": False, \"categorieJuridiqueUniteLegale\": \"1000\", \"changementCategorieJuridiqueUniteLegale\": False, \"activitePrincipaleUniteLegale\": \"66.22Z\", \"nomenclatureActivitePrincipaleUniteLegale\": \"NAFRev2\", \"changementActivitePrincipaleUniteLegale\": False, \"nicSiegeUniteLegale\": \"00014\", \"changementNicSiegeUniteLegale\": False, \"economieSocialeSolidaireUniteLegale\": None, \"changementEconomieSocialeSolidaireUniteLegale\": False, \"societeMissionUniteLegale\": None, \"changementSocieteMissionUniteLegale\": False, \"caractereEmployeurUniteLegale\": None, \"changementCaractereEmployeurUniteLegale\": False}, {\"dateFin\": \"2008-12-30\", \"dateDebut\": \"2008-01-01\", \"etatAdministratifUniteLegale\": \"A\", \"changementEtatAdministratifUniteLegale\": False, \"nomUniteLegale\": \"VIALLA\", \"changementNomUniteLegale\": False, \"nomUsageUniteLegale\": None, \"changementNomUsageUniteLegale\": False, \"denominationUniteLegale\": None, \"changementDenominationUniteLegale\": False, \"denominationUsuelle1UniteLegale\": None, \"denominationUsuelle2UniteLegale\": None, \"denominationUsuelle3UniteLegale\": None, \"changementDenominationUsuelleUniteLegale\": False, \"categorieJuridiqueUniteLegale\": \"1000\", \"changementCategorieJuridiqueUniteLegale\": False, \"activitePrincipaleUniteLegale\": \"66.22Z\", \"nomenclatureActivitePrincipaleUniteLegale\": \"NAFRev2\", \"changementActivitePrincipaleUniteLegale\": True, \"nicSiegeUniteLegale\": \"00014\", \"changementNicSiegeUniteLegale\": False, \"economieSocialeSolidaireUniteLegale\": None, \"changementEconomieSocialeSolidaireUniteLegale\": False, \"societeMissionUniteLegale\": None, \"changementSocieteMissionUniteLegale\": False, \"caractereEmployeurUniteLegale\": None, \"changementCaractereEmployeurUniteLegale\": False}, {\"dateFin\": \"2007-12-31\", \"dateDebut\": \"1979-12-25\", \"etatAdministratifUniteLegale\": \"A\", \"changementEtatAdministratifUniteLegale\": False, \"nomUniteLegale\": \"VIALLA\", \"changementNomUniteLegale\": False, \"nomUsageUniteLegale\": None, \"changementNomUsageUniteLegale\": False, \"denominationUniteLegale\": None, \"changementDenominationUniteLegale\": False, \"denominationUsuelle1UniteLegale\": None, \"denominationUsuelle2UniteLegale\": None, \"denominationUsuelle3UniteLegale\": None, \"changementDenominationUsuelleUniteLegale\": False, \"categorieJuridiqueUniteLegale\": \"1000\", \"changementCategorieJuridiqueUniteLegale\": False, \"activitePrincipaleUniteLegale\": \"67.2Z\", \"nomenclatureActivitePrincipaleUniteLegale\": \"NAF1993\", \"changementActivitePrincipaleUniteLegale\": True, \"nicSiegeUniteLegale\": \"00014\", \"changementNicSiegeUniteLegale\": False, \"economieSocialeSolidaireUniteLegale\": None, \"changementEconomieSocialeSolidaireUniteLegale\": False, \"societeMissionUniteLegale\": None, \"changementSocieteMissionUniteLegale\": False, \"caractereEmployeurUniteLegale\": None, \"changementCaractereEmployeurUniteLegale\": False}, {\"dateFin\": \"1979-12-24\", \"dateDebut\": \"1900-01-01\", \"etatAdministratifUniteLegale\": \"A\", \"changementEtatAdministratifUniteLegale\": False, \"nomUniteLegale\": \"VIALLA\", \"changementNomUniteLegale\": False, \"nomUsageUniteLegale\": None, \"changementNomUsageUniteLegale\": False, \"denominationUniteLegale\": None, \"changementDenominationUniteLegale\": False, \"denominationUsuelle1UniteLegale\": None, \"denominationUsuelle2UniteLegale\": None, \"denominationUsuelle3UniteLegale\": None, \"changementDenominationUsuelleUniteLegale\": False, \"categorieJuridiqueUniteLegale\": \"1000\", \"changementCategorieJuridiqueUniteLegale\": False, \"activitePrincipaleUniteLegale\": None, \"nomenclatureActivitePrincipaleUniteLegale\": None, \"changementActivitePrincipaleUniteLegale\": False, \"nicSiegeUniteLegale\": \"00014\", \"changementNicSiegeUniteLegale\": False, \"economieSocialeSolidaireUniteLegale\": None, \"changementEconomieSocialeSolidaireUniteLegale\": False, \"societeMissionUniteLegale\": None, \"changementSocieteMissionUniteLegale\": False, \"caractereEmployeurUniteLegale\": None, \"changementCaractereEmployeurUniteLegale\": False}]}\n"
     ]
    }
   ],
   "source": [
    "# Print out the problematic JSON string\n",
    "print(df_csv['unitesLegales'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAND BOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['insee_list_04_2024.csv', 'insee_list_04_202410.csv', 'insee_list_04_202411.csv', 'insee_list_04_202412.csv', 'insee_list_04_202413.csv', 'insee_list_04_202414.csv', 'insee_list_04_202415.csv', 'insee_list_04_202416.csv', 'insee_list_04_202417.csv', 'insee_list_04_202418.csv', 'insee_list_04_202419.csv', 'insee_list_04_20242.csv', 'insee_list_04_202420.csv', 'insee_list_04_202421.csv', 'insee_list_04_202422.csv', 'insee_list_04_202423.csv', 'insee_list_04_202424.csv', 'insee_list_04_202425.csv', 'insee_list_04_202426.csv', 'insee_list_04_202427.csv', 'insee_list_04_202428.csv', 'insee_list_04_202429.csv', 'insee_list_04_20243.csv', 'insee_list_04_202431.csv', 'insee_list_04_202432.csv', 'insee_list_04_202433.csv', 'insee_list_04_202434.csv', 'insee_list_04_202435.csv', 'insee_list_04_202436.csv', 'insee_list_04_202437.csv', 'insee_list_04_202438.csv', 'insee_list_04_202439.csv', 'insee_list_04_20244.csv', 'insee_list_04_202440.csv', 'insee_list_04_202441.csv', 'insee_list_04_202442.csv', 'insee_list_04_202443.csv', 'insee_list_04_202444.csv', 'insee_list_04_202445.csv', 'insee_list_04_2024456.csv', 'insee_list_04_202447.csv', 'insee_list_04_202448.csv', 'insee_list_04_202449.csv', 'insee_list_04_20245.csv', 'insee_list_04_202450.csv', 'insee_list_04_202451.csv', 'insee_list_04_202452.csv', 'insee_list_04_202453.csv', 'insee_list_04_202454.csv', 'insee_list_04_202455.csv', 'insee_list_04_202456.csv', 'insee_list_04_202457.csv', 'insee_list_04_202458.csv', 'insee_list_04_202459.csv', 'insee_list_04_20246.csv', 'insee_list_04_202460.csv', 'insee_list_04_202461.csv', 'insee_list_04_202462.csv', 'insee_list_04_202463.csv', 'insee_list_04_202464.csv', 'insee_list_04_202465.csv', 'insee_list_04_202466.csv', 'insee_list_04_202467.csv', 'insee_list_04_202468.csv', 'insee_list_04_202469.csv', 'insee_list_04_20247.csv', 'insee_list_04_202470.csv', 'insee_list_04_202471.csv', 'insee_list_04_202472.csv', 'insee_list_04_202473.csv', 'insee_list_04_202474.csv', 'insee_list_04_202475.csv', 'insee_list_04_202476.csv', 'insee_list_04_202477.csv', 'insee_list_04_20248.csv', 'insee_list_04_20249.csv']\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'insee_list_04_2024_all.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[315], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m                 writer\u001b[38;5;241m.\u001b[39mwriterow(row)\n\u001b[0;32m     36\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsee_list_04_2024_all.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 37\u001b[0m \u001b[43mmerge_csv_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsurers_list_till_04_2024_all\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[315], line 28\u001b[0m, in \u001b[0;36mmerge_csv_files\u001b[1;34m(input_files, output_file)\u001b[0m\n\u001b[0;32m     23\u001b[0m             reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(input_csvfile)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#open main csv fil which will append other files // newline=''\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m output_csv_file:\n\u001b[0;32m     29\u001b[0m             fieldnames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munitesLegales\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     30\u001b[0m             writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictWriter(output_csv_file, fieldnames\u001b[38;5;241m=\u001b[39mfieldnames)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'insee_list_04_2024_all.csv'"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#initial state of variables\n",
    "input_files = []\n",
    "directory = 'C:/Users/BGE/Google Drive/GIT/API'\n",
    "\n",
    "#establish a list of files in main directory and transform in pd\n",
    "all_files = os.listdir(directory)\n",
    "all_files = pd.DataFrame(all_files).to_string()\n",
    "\n",
    "#fill input_files with file names concerned by the mergin operation, defined through regex search  \n",
    "input_files = re.findall(r\"insee_list_04_2024.{0,3}\\.csv\", all_files )\n",
    "print(input_files)\n",
    "\n",
    "# define merge function\n",
    "def merge_csv_files(input_files, output_file):\n",
    "    for input_file in input_files:\n",
    "        with open(input_file, 'r', newline='') as input_csvfile:\n",
    "            reader = csv.reader(input_csvfile)\n",
    "                \n",
    "            \n",
    "\n",
    "#open main csv fil which will append other files // newline=''\n",
    "        with open(output_file, 'w', newline='' ) as output_csv_file:\n",
    "            fieldnames = ['unitesLegales']\n",
    "            writer = csv.DictWriter(output_csv_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()  # Write header row\n",
    "            # writer.writerow(input_file)  # Write data row\n",
    "            for row in input_csvfile:\n",
    "                writer.writerow(row)\n",
    "\n",
    "output_file = 'insee_list_04_2024_all.csv'\n",
    "merge_csv_files(input_files, output_file)\n",
    "\n",
    "try:\n",
    "    os.makedirs('insurers_list_till_04_2024_all')\n",
    "    shutil.move(insee_list_04_2024_all.csv, insurers_list_till_04_2024_all)\n",
    "except FileExistsError as e:\n",
    "    # Handle the exception\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    continue\n",
    "else:\n",
    "    # If no exception occurs, continue execution\n",
    "    print(\"Directory created successfully.\")\n",
    "    # Continue with the rest of your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
